<html lang="en"><head><script>(function(firebaseConfig, initialAuthToken, appId) {
        window.__firebase_config = firebaseConfig;
        window.__initial_auth_token = initialAuthToken;
        window.__app_id = appId;
            })("\n{\n  \"apiKey\": \"AIzaSyCqyCcs2R2e7AegGjvFAwG98wlamtbHvZY\",\n  \"authDomain\": \"bard-frontend.firebaseapp.com\",\n  \"projectId\": \"bard-frontend\",\n  \"storageBucket\": \"bard-frontend.firebasestorage.app\",\n  \"messagingSenderId\": \"175205271074\",\n  \"appId\": \"1:175205271074:web:2b7bd4d34d33bf38e6ec7b\"\n}\n","eyJhbGciOiJSUzI1NiIsImtpZCI6IjY0ZjA3ZDcxOTc5ZjQzODI3MjJhOGRmMzQwNzUzY2UwZmVkOThjYTgiLCJ0eXAiOiJKV1QifQ.eyJzdWIiOiJmaXJlYmFzZS1hZG1pbnNkay1mYnN2Y0BiYXJkLWZyb250ZW5kLmlhbS5nc2VydmljZWFjY291bnQuY29tIiwiYXVkIjoiaHR0cHM6Ly9pZGVudGl0eXRvb2xraXQuZ29vZ2xlYXBpcy5jb20vZ29vZ2xlLmlkZW50aXR5LmlkZW50aXR5dG9vbGtpdC52MS5JZGVudGl0eVRvb2xraXQiLCJ1aWQiOiIxNjE3ODc1MTc1MzkzMjgxMjYwMyIsImlzcyI6ImZpcmViYXNlLWFkbWluc2RrLWZic3ZjQGJhcmQtZnJvbnRlbmQuaWFtLmdzZXJ2aWNlYWNjb3VudC5jb20iLCJjbGFpbXMiOnsiYXBwSWQiOiJjXzQ2ZGU4ODM1Mzk1NGI5MmZfZmFzdF9pbmZlcmVuY2Vfd2Fsa3Rocm91Z2guaHRtbC05MzQifSwiZXhwIjoxNzcwODY4NzI5LCJpYXQiOjE3NzA4NjUxMjksImFsZyI6IlJTMjU2In0.Ug13LATGy3YebxXdRq6qxlCW_pTDA9kFuaaeZ5M7tuvprjdCW1gNU1vDbtP0m8e2htrvYkvviSd9VcJRFO-JzYLalG4tce0KyFNoEJrCAfBEU2mGKgpyRDZTXQpdgHNOMzUb_K7V6LHVfzJyliEao5vIWIuQkAycwQ7EfCJRKhJk-ShAulnVbtkXKh7q3VvtS9LT8o1EpZ1K02QJbs702MCuM47nW5QHKJjy53S9NeGybCAcQxrLID7kEg297tdQ4lmq8ujogWF91Asy7OzOuCEkhBP8qlcTmNy13HXeC0bCp4t26A_dzZnWJ9X8t-UjZr4ZnppWsF-jVJlXSD9FLg","c_46de88353954b92f_fast_inference_walkthrough.html-934")</script><script>'use strict';var h=typeof Object.defineProperties=="function"?Object.defineProperty:function(a,b,d){if(a==Array.prototype||a==Object.prototype)return a;a[b]=d.value;return a};function l(a){a=["object"==typeof globalThis&&globalThis,a,"object"==typeof window&&window,"object"==typeof self&&self,"object"==typeof global&&global];for(var b=0;b<a.length;++b){var d=a[b];if(d&&d.Math==Math)return d}throw Error("Cannot find global object");}var n=l(this);
function p(a,b){if(b)a:{var d=n;a=a.split(".");for(var c=0;c<a.length-1;c++){var e=a[c];if(!(e in d))break a;d=d[e]}a=a[a.length-1];c=d[a];b=b(c);b!=c&&b!=null&&h(d,a,{configurable:!0,writable:!0,value:b})}}function r(a){function b(c){return a.next(c)}function d(c){return a.throw(c)}return new Promise(function(c,e){function f(g){g.done?c(g.value):Promise.resolve(g.value).then(b,d).then(f,e)}f(a.next())})}function t(a){return r(a())}
p("Object.values",function(a){return a?a:function(b){var d=[],c;for(c in b)Object.prototype.hasOwnProperty.call(b,c)&&d.push(b[c]);return d}});p("Array.prototype.includes",function(a){return a?a:function(b,d){var c=this;c instanceof String&&(c=String(c));var e=c.length;d=d||0;for(d<0&&(d=Math.max(d+e,0));d<e;d++){var f=c[d];if(f===b||Object.is(f,b))return!0}return!1}});/*

 MIT License

 Copyright (c) 2017-2023 W.Y.

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 SOFTWARE.

*/
function u(a,b){const d=a.style;b.backgroundColor&&(d.backgroundColor=b.backgroundColor);b.width&&(d.width=`${b.width}px`);b.height&&(d.height=`${b.height}px`);const c=b.style;c!=null&&Object.keys(c).forEach(e=>{d[e]=c[e]})};var v=(()=>{let a=0;return()=>{a+=1;return`u${`0000${(Math.random()*1679616<<0).toString(36)}`.slice(-4)}${a}`}})();function w(a){const b=[];for(let d=0,c=a.length;d<c;d++)b.push(a[d]);return b}let x=null;function y(a={}){return x?x:a.l?x=a.l:x=w(window.getComputedStyle(document.documentElement))}function z(a,b){return(a=(a.ownerDocument.defaultView||window).getComputedStyle(a).getPropertyValue(b))?parseFloat(a.replace("px","")):0}
function A(a,b={}){var d;if(!(d=b.width)){d=z(a,"border-left-width");var c=z(a,"border-right-width");d=a.clientWidth+d+c}(b=b.height)||(b=z(a,"border-top-width"),c=z(a,"border-bottom-width"),b=a.clientHeight+b+c);return{width:d,height:b}}function B(a){return new Promise((b,d)=>{const c=new Image;c.onload=()=>{c.decode().then(()=>{requestAnimationFrame(()=>b(c))})};c.onerror=d;c.crossOrigin="anonymous";c.decoding="async";c.src=a})}
function C(a){return t(function*(){return Promise.resolve().then(()=>(new XMLSerializer).serializeToString(a)).then(encodeURIComponent).then(b=>`data:image/svg+xml;charset=utf-8,${b}`)})}
function D(a,b,d){return t(function*(){const c=document.createElementNS("http://www.w3.org/2000/svg","svg"),e=document.createElementNS("http://www.w3.org/2000/svg","foreignObject");c.setAttribute("width",`${b}`);c.setAttribute("height",`${d}`);c.setAttribute("viewBox",`0 0 ${b} ${d}`);e.setAttribute("width","100%");e.setAttribute("height","100%");e.setAttribute("x","0");e.setAttribute("y","0");e.setAttribute("externalResourcesRequired","true");c.appendChild(e);e.appendChild(a);return C(c)})}
var E=(a,b)=>{if(a instanceof b)return!0;a=Object.getPrototypeOf(a);return a===null?!1:a.constructor.name===b.name||E(a,b)};function F(a,b){return y(b).map(d=>{const c=a.getPropertyValue(d),e=a.getPropertyPriority(d);return`${d}: ${c}${e?" !important":""};`}).join(" ")}
function G(a,b,d,c){a=window.getComputedStyle(a,d);var e=a.getPropertyValue("content");if(e!==""&&e!=="none"){var f=v();try{b.className=`${b.className} ${f}`}catch(k){return}e=document.createElement("style");var g=e.appendChild;d=`.${f}:${d}`;a.cssText?(c=a.getPropertyValue("content"),c=`${a.cssText} content: '${c.replace(/'|"/g,"")}';`):c=F(a,c);g.call(e,document.createTextNode(`${d}{${c}}`));b.appendChild(e)}};function H(a){return a.search(/^(data:)/)!==-1}function I(a,b,d){return t(function*(){const c=yield fetch(a,b);if(c.status===404)throw Error(`Resource "${c.url}" not found`);const e=yield c.blob();return new Promise((f,g)=>{const k=new FileReader;k.onerror=g;k.onloadend=()=>{try{f(d({o:c,result:k.result}))}catch(m){g(m)}};k.readAsDataURL(e)})})}const J={};function K(a,b,d){let c=a.replace(/\?.*/,"");d&&(c=a);/ttf|otf|eot|woff2?/i.test(c)&&(c=c.replace(/.*\//,""));return b?`[${b}]${c}`:c}
function L(a,b,d){return t(function*(){const c=K(a,b,d.C);if(J[c]!=null)return J[c];d.u&&(a+=(/\?/.test(a)?"&":"?")+(new Date).getTime());let e;try{const f=yield I(a,d.i,({o:g,result:k})=>{b||(b=g.headers.get("Content-Type")||"");return k.split(/,/)[1]});e=`data:${b};base64,${f}`}catch(f){e=d.B||""}return J[c]=e})};const M={P:"application/font-woff",R:"application/font-woff",N:"application/font-truetype",v:"application/vnd.ms-fontobject",H:"image/png",F:"image/jpeg",D:"image/jpeg",A:"image/gif",M:"image/tiff",L:"image/svg+xml",O:"image/webp"};function N(a){return(a=/\.([^./]*?)$/g.exec(a))?a[1]:""};function O(a){return t(function*(){const b=a.toDataURL();return b==="data:,"?a.cloneNode(!1):B(b)})}function aa(a,b){return t(function*(){if(a.currentSrc){var d=document.createElement("canvas");const c=d.getContext("2d");d.width=a.clientWidth;d.height=a.clientHeight;c==null||c.drawImage(a,0,0,d.width,d.height);d=d.toDataURL();return B(d)}d=a.poster;d=yield L(d,M[N(d).toLowerCase()]||"",b);return B(d)})}
function ba(a,b){return t(function*(){try{let d;if(a==null?0:(d=a.contentDocument)==null?0:d.body)return yield P(a.contentDocument.body,b,!0)}catch(d){}return a.cloneNode(!1)})}function ca(a,b){return t(function*(){return E(a,HTMLCanvasElement)?O(a):E(a,HTMLVideoElement)?aa(a,b):E(a,HTMLIFrameElement)?ba(a,b):a.cloneNode(a.tagName!=null&&a.tagName.toUpperCase()==="SVG")})}
function da(a,b,d){return t(function*(){if(b.tagName!=null&&b.tagName.toUpperCase()==="SVG")return b;let c=[];if(a.tagName!=null&&a.tagName.toUpperCase()==="SLOT"&&a.assignedNodes)c=w(a.assignedNodes());else{let e;if(E(a,HTMLIFrameElement)&&((e=a.contentDocument)==null?0:e.body))c=w(a.contentDocument.body.childNodes);else{let f;c=w(((f=a.shadowRoot)!=null?f:a).childNodes)}}if(c.length===0||E(a,HTMLVideoElement))return b;yield c.reduce((e,f)=>e.then(()=>P(f,d)).then(g=>{g&&b.appendChild(g)}),Promise.resolve());
return b})}function ea(a,b,d){const c=b.style;if(c){var e=window.getComputedStyle(a);e.cssText?(c.cssText=e.cssText,c.transformOrigin=e.transformOrigin):y(d).forEach(f=>{let g=e.getPropertyValue(f);f==="font-size"&&g.endsWith("px")&&(g=`${Math.floor(parseFloat(g.substring(0,g.length-2)))-.1}px`);E(a,HTMLIFrameElement)&&f==="display"&&g==="inline"&&(g="block");f==="d"&&b.getAttribute("d")&&(g=`path(${b.getAttribute("d")})`);c.setProperty(f,g,e.getPropertyPriority(f))})}}
function fa(a,b){E(a,HTMLSelectElement)&&(b=Array.from(b.children).find(d=>a.value===d.getAttribute("value")))&&b.setAttribute("selected","")}
function ha(a,b){return t(function*(){var d=a.querySelectorAll?a.querySelectorAll("use"):[];if(d.length===0)return a;var c={};for(var e=0;e<d.length;e++){var f=d[e].getAttribute("xlink:href");if(f){const g=document.querySelector(f);a.querySelector(f)||!g||c[f]||(c[f]=yield P(g,b,!0))}}d=Object.values(c);if(d.length){c=document.createElementNS("http://www.w3.org/1999/xhtml","svg");c.setAttribute("xmlns","http://www.w3.org/1999/xhtml");c.style.position="absolute";c.style.width="0";c.style.height="0";
c.style.overflow="hidden";c.style.display="none";e=document.createElementNS("http://www.w3.org/1999/xhtml","defs");c.appendChild(e);for(f=0;f<d.length;f++)e.appendChild(d[f]);a.appendChild(c)}return a})}
function P(a,b,d){return t(function*(){return d||!b.filter||b.filter(a)?Promise.resolve(a).then(c=>ca(c,b)).then(c=>da(a,c,b)).then(c=>{E(c,Element)&&(ea(a,c,b),G(a,c,":before",b),G(a,c,":after",b),E(a,HTMLTextAreaElement)&&(c.textContent=a.value),E(a,HTMLInputElement)&&c.setAttribute("value",a.value),fa(a,c));return c}).then(c=>ha(c,b)):null})};const Q=/url\((['"]?)([^'"]+?)\1\)/g,ia=/url\([^)]+\)\s*format\((["']?)([^"']+)\1\)/g,ja=/src:\s*(?:url\([^)]+\)\s*format\([^)]+\)[,;]\s*)+/g;function ka(a){const b=[];a.replace(Q,(d,c,e)=>{b.push(e);return d});return b.filter(d=>!H(d))}
function la(a,b,d,c){return t(function*(){try{const e=d?(new URL(b,d||void 0)).toString():b;let f;f=yield L(e,M[N(b).toLowerCase()]||"",c);return a.replace(new RegExp(`(url\\(['"]?)(${b.replace(/([.*+?^${}()|\[\]\/\\])/g,"\\$1")})(['"]?\\))`,"g"),`$1${f}$3`)}catch(e){}return a})}function ma(a,{I:b}){return b?a.replace(ja,d=>{for(;;){const [c,,e]=ia.exec(d)||[],f=c,g=e;if(!g)return"";if(g===b)return`src: ${f};`}}):a}
function R(a,b,d){return t(function*(){if(a.search(Q)===-1)return a;const c=ma(a,d);return ka(c).reduce((e,f)=>e.then(g=>la(g,f,b,d)),Promise.resolve(c))})};function S(a,b,d){return t(function*(){var c;const e=(c=b.style)==null?void 0:c.getPropertyValue(a);return e?(c=yield R(e,null,d),b.style.setProperty(a,c,b.style.getPropertyPriority(a)),!0):!1})}function na(a,b){return t(function*(){(yield S("background",a,b))||(yield S("background-image",a,b));(yield S("mask",a,b))||(yield S("-webkit-mask",a,b))||(yield S("mask-image",a,b))||(yield S("-webkit-mask-image",a,b))})}
function oa(a,b){return t(function*(){const d=E(a,HTMLImageElement);if(d&&!H(a.src)||E(a,SVGImageElement)&&!H(a.href.baseVal)){var c=d?a.src:a.href.baseVal,e=yield L(c,M[N(c).toLowerCase()]||"",b);yield new Promise((f,g)=>{a.onload=f;a.onerror=b.m?(...k)=>{try{f(b.m(...k))}catch(m){g(m)}}:g;a.decode&&(a.decode=f);a.loading==="lazy"&&(a.loading="eager");d?(a.srcset="",a.src=e):a.href.baseVal=e})}})}
function pa(a,b){return t(function*(){const d=w(a.childNodes).map(c=>T(c,b));yield Promise.all(d).then(()=>a)})}function T(a,b){return t(function*(){E(a,Element)&&(yield na(a,b),yield oa(a,b),yield pa(a,b))})};const U={};function V(a){return t(function*(){var b=U[a];if(b!=null)return b;b=yield(yield fetch(a)).text();b={url:a,cssText:b};return U[a]=b})}function W(a,b){return t(function*(){let d=a.cssText;const c=/url\(["']?([^"')]+)["']?\)/g,e=(d.match(/url\([^)]+\)/g)||[]).map(f=>t(function*(){let g=f.replace(c,"$1");g.startsWith("https://")||(g=(new URL(g,a.url)).href);return I(g,b.i,({result:k})=>{d=d.replace(f,`url(${k})`);return[f,k]})}));return Promise.all(e).then(()=>d)})}
function X(a){if(a==null)return[];const b=[];a=a.replace(/(\/\*[\s\S]*?\*\/)/gi,"");for(var d=RegExp("((@.*?keyframes [\\s\\S]*?){([\\s\\S]*?}\\s*?)})","gi");;){var c=d.exec(a);if(c===null)break;b.push(c[0])}a=a.replace(d,"");d=/@import[\s\S]*?url\([^)]*\)[\s\S]*?;/gi;for(c=RegExp("((\\s*?(?:\\/\\*[\\s\\S]*?\\*\\/)?\\s*?@media[\\s\\S]*?){([\\s\\S]*?)}\\s*?})|(([\\s\\S]*?){([\\s\\S]*?)})","gi");;){let e=d.exec(a);if(e===null)if(e=c.exec(a),e===null)break;else d.lastIndex=c.lastIndex;else c.lastIndex=
d.lastIndex;b.push(e[0])}return b}
function qa(a,b){return t(function*(){const d=[],c=[];a.forEach(e=>{if("cssRules"in e)try{w(e.cssRules||[]).forEach((f,g)=>{if(f.type===CSSRule.IMPORT_RULE){let k=g+1;f=V(f.href).then(m=>W(m,b)).then(m=>X(m).forEach(q=>{try{e.insertRule(q,q.startsWith("@import")?k+=1:e.cssRules.length)}catch(Da){}})).catch(()=>{});c.push(f)}})}catch(f){const g=a.find(k=>k.href==null)||document.styleSheets[0];e.href!=null&&c.push(V(e.href).then(k=>W(k,b)).then(k=>X(k).forEach(m=>{g.insertRule(m,g.cssRules.length)})).catch(()=>
{}))}});return Promise.all(c).then(()=>{a.forEach(e=>{if("cssRules"in e)try{w(e.cssRules||[]).forEach(f=>{d.push(f)})}catch(f){}});return d})})}function ra(a){return a.filter(b=>b.type===CSSRule.FONT_FACE_RULE).filter(b=>b.style.getPropertyValue("src").search(Q)!==-1)}function sa(a,b){return t(function*(){if(a.ownerDocument==null)throw Error("Provided element is not within a Document");var d=w(a.ownerDocument.styleSheets);d=yield qa(d,b);return ra(d)})}
function ta(a){function b(c){(c.style.fontFamily||getComputedStyle(c).fontFamily).split(",").forEach(e=>{d.add(e.trim().replace(/["']/g,""))});Array.from(c.children).forEach(e=>{e instanceof HTMLElement&&b(e)})}const d=new Set;b(a);return d}function ua(a,b){return t(function*(){const d=yield sa(a,b),c=ta(a);return(yield Promise.all(d.filter(e=>c.has(e.style.fontFamily.trim().replace(/["']/g,""))).map(e=>R(e.cssText,e.parentStyleSheet?e.parentStyleSheet.href:null,b)))).join("\n")})}
function va(a,b){return t(function*(){const d=b.j!=null?b.j:b.K?null:yield ua(a,b);if(d){const c=document.createElement("style");c.appendChild(document.createTextNode(d));a.firstChild?a.insertBefore(c,a.firstChild):a.appendChild(c)}})};function wa(a,b={}){return t(function*(){const {width:d,height:c}=A(a,b),e=yield P(a,b,!0);yield va(e,b);yield T(e,b);u(e,b);return yield D(e,d,c)})}
function xa(a,b={}){return t(function*(){const {width:d,height:c}=A(a,b);var e=yield wa(a,b);e=yield B(e);const f=document.createElement("canvas"),g=f.getContext("2d"),k=b.G||window.devicePixelRatio||1,m=b.h||d,q=b.g||c;f.width=m*k;f.height=q*k;!b.J&&(f.width>16384||f.height>16384)&&(f.width>16384&&f.height>16384?f.width>f.height?(f.height*=16384/f.width,f.width=16384):(f.width*=16384/f.height,f.height=16384):f.width>16384?(f.height*=16384/f.width,f.width=16384):(f.width*=16384/f.height,f.height=
16384));f.style.width=`${m}`;f.style.height=`${q}`;b.backgroundColor&&(g.fillStyle=b.backgroundColor,g.fillRect(0,0,f.width,f.height));g.drawImage(e,0,0,f.width,f.height);return f})}function ya(a,b={}){return t(function*(){return(yield xa(a,b)).toDataURL()})};const za=["gemini.google.com","corp.google.com","proxy.googlers.com"];function Y(){return document.body.querySelectorAll('[class*="animate"]').length>0}function Z(a){return t(function*(){try{return yield ya(a,{h:a.offsetWidth,g:a.offsetHeight})}catch(d){var b=a.offsetHeight;const c=document.createElement("canvas");c.width=a.offsetWidth;c.height=b;return c.toDataURL("image/png")}})}
function Aa(){return t(function*(){const a=document.body.offsetWidth,b=document.body.offsetHeight,d=document.body.cloneNode(!0);d.querySelectorAll('[class*="animate"]').forEach(c=>{c.classList.remove(...Array.from(c.classList).filter(e=>e.startsWith("animate")))});d.style.width=`${a}px`;d.style.height=`${b}px`;return d})}
function Ba(a){return t(function*(){let b=document.body;if(Y()){var d=yield Aa();b=d;document.body.appendChild(d)}d=yield Z(b);Y()&&document.body.removeChild(b);window.parent.postMessage({type:"SEND_SCREENSHOT",image:d,topOffset:document.documentElement.scrollTop},a.origin)})}function Ca(a){return t(function*(){const b={type:"SEND_SCREENSHOT_FOR_DATA_VISUALIZATION",image:yield Z(document.body),topOffset:0};window.parent.postMessage(b,a.origin)})}
window.addEventListener("message",a=>t(function*(){if(za.some(d=>a.origin.includes(d))){var b=a.data;b&&(b.type==="MAKE_SCREENSHOT"&&(yield Ba(a)),b.type==="MAKE_SCREENSHOT_FOR_DATA_VISUALIZATION"&&(yield Ca(a)))}}));
</script><script>(function() {
  // Ensure this script is executed only once
  if (window.firebaseAuthBridgeScriptLoaded) {
    return;
  }
  window.firebaseAuthBridgeScriptLoaded = true;

  let nextTokenPromiseId = 0;

  // Stores { resolve, reject } for ongoing token requests
  const pendingTokenPromises = {};

  // Listen for messages from the Host Application
  window.addEventListener('message', function(event) {

    const messageData = event.data;

  if (messageData && messageData.type === 'RESOLVE_NEW_FIREBASE_TOKEN') {
      const { success, token, error, promiseId } = messageData ?? {};
      if (pendingTokenPromises[promiseId]) {
        if (success) {
          pendingTokenPromises[promiseId].resolve(token);
        } else {
          pendingTokenPromises[promiseId].reject(new Error(error || 'Token refresh failed from host.'));
        }
        delete pendingTokenPromises[promiseId];
      }
    }
  });

  // Expose a function for the Generated App to request a new Firebase token
  window.requestNewFirebaseToken = function() {
    const currentPromiseId = nextTokenPromiseId++;
    const promise = new Promise((resolve, reject) => {
      pendingTokenPromises[currentPromiseId] = { resolve, reject };
    });
    if (window.parent && window.parent !== window) {
      window.parent.postMessage({
        type: 'REQUEST_NEW_FIREBASE_TOKEN',
        promiseId: currentPromiseId
      }, '*');
    } else {
      pendingTokenPromises[currentPromiseId].reject(new Error('No parent window to request token from.'));
      delete pendingTokenPromises[currentPromiseId];
    }
    return promise;
  };
})();</script><script>
let realOriginalGetUserMedia = null;
if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
  realOriginalGetUserMedia = navigator.mediaDevices.getUserMedia.bind(navigator.mediaDevices);
}

(function() {
  if (navigator.mediaDevices && navigator.mediaDevices.__proto__) {
    try {
      Object.defineProperty(navigator.mediaDevices.__proto__, 'getUserMedia', {
        get: function() {
          return undefined; // Or throw an error
        },
        configurable: false
      });
    } catch (error) {
      console.error("Error defining prototype getter:", error);
    }
  }
})();

(function() {
  const pendingMediaResolvers = {};
  let nextMediaPromiseId = 0;

  function requestMediaPermissions(constraints) {
    const mediaPromiseId = nextMediaPromiseId++;
    const promise = new Promise((resolve, reject) => {
      pendingMediaResolvers[mediaPromiseId] = (granted) => {
        delete pendingMediaResolvers[mediaPromiseId];
        resolve(granted);
      };
    });

    window.parent.postMessage({
      type: 'requestMediaPermission',
      constraints: constraints,
      promiseId: mediaPromiseId,
    }, '*');

    return promise;
  }

  let originalGetUserMedia = realOriginalGetUserMedia;

  function interceptGetUserMedia() {
    if (navigator.mediaDevices) {
      Object.defineProperty(navigator.mediaDevices, 'getUserMedia', {
        value: function(constraints) {
          return requestMediaPermissions(constraints).then((granted) => {
            if (granted) {
              if (originalGetUserMedia) {
                return originalGetUserMedia(constraints);
              } else {
                throw new Error("Original getUserMedia not available.");
              }
            } else {
              throw new DOMException('Permission denied', 'NotAllowedError');
            }
          });
        },
        writable: false,
        configurable: false
      });
    }
  }

  interceptGetUserMedia();

  const observer = new MutationObserver(function(mutationsList, observer) {
    for (const mutation of mutationsList) {
      if (mutation.type === 'reconfigured' && mutation.name === 'getUserMedia' && mutation.object === navigator.mediaDevices) {
        interceptGetUserMedia();
      } else if (mutation.type === 'attributes' && mutation.attributeName === 'getUserMedia' && mutation.target === navigator.mediaDevices) {
        interceptGetUserMedia();
      } else if (mutation.type === 'childList' && mutation.addedNodes) {
        mutation.addedNodes.forEach(node => {
          if (node === navigator.mediaDevices) {
            interceptGetUserMedia();
          }
        });
      }
    }
  });

  function interceptSpeechRecognition() {
    if (!window.SpeechRecognition && !window.webkitSpeechRecognition) {
      return;
    }

    const OriginalSpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    const SpeechRecognitionWrapper = function(...args) {
      const recognizer = new OriginalSpeechRecognition(...args);
      const originalStart = recognizer.start.bind(recognizer);

      recognizer.start = function() {
        requestMediaPermissions({ audio: true }).then(granted => {
          if (granted) {
            originalStart();
          } else {
            const errorEvent = new SpeechRecognitionErrorEvent('error');
            errorEvent.error = 'not-allowed'; // This is the standard error for permission denial.
            recognizer.dispatchEvent(errorEvent);
          }
        });
      };

      return recognizer;
    };

    SpeechRecognitionWrapper.prototype = OriginalSpeechRecognition.prototype;
    SpeechRecognitionWrapper.prototype.constructor = SpeechRecognitionWrapper;

    if (window.SpeechRecognition) {
      window.SpeechRecognition = SpeechRecognitionWrapper;
    }
    if (window.webkitSpeechRecognition) {
      window.webkitSpeechRecognition = SpeechRecognitionWrapper;
    }
  }

  interceptSpeechRecognition();

  window.addEventListener('message', function(event) {
    if (event.data) {
      if (event.data.type === 'resolveMediaPermission') {
        const { promiseId, granted } = event.data;
        if (pendingMediaResolvers[promiseId]) {
          pendingMediaResolvers[promiseId](granted);
        }
      }
    }
  });

})();</script><script>((function(modelInformation) {
  const originalFetch = window.fetch;
  // TODO: b/421908508 - Move these out of the script and match all generative AI model calls.
  let googleLlmBaseApiUrls = [
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.textModelName + ':streamGenerateContent',
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.textModelName + ':generateContent',
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.imageModelName + ':predict',
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.imageModelName + ':predictLongRunning',
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.imageEditModelName + ':generateContent',
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.imageTransformModelName + ':generateContent',
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.videoModelName + ':predict',
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.videoModelName + ':predictLongRunning',
    'https://generativelanguage.googleapis.com/v1beta/models/' + modelInformation.ttsModelName + ':generateContent',
  ];
  modelInformation.deprecatedTextModelNames.forEach((modelName) => {
    googleLlmBaseApiUrls.push(
      'https://generativelanguage.googleapis.com/v1beta/models/' + modelName + ':streamGenerateContent',
      'https://generativelanguage.googleapis.com/v1beta/models/' + modelName + ':generateContent',
    );
  });
  modelInformation.deprecatedImageModelNames.forEach((modelName) => {
    googleLlmBaseApiUrls.push(
      'https://generativelanguage.googleapis.com/v1beta/models/' + modelName + ':predict',
      'https://generativelanguage.googleapis.com/v1beta/models/' + modelName + ':predictLongRunning',
    );
  });

  const pendingFetchResolvers = {};
  let nextPromiseId = 0;

  function handleStringInput(input, optionsArgument) {
    const actualUrl = input;
    const fetchCallArgs = [actualUrl, optionsArgument];
    const effectiveOptions = optionsArgument || {};
    const bodyForApiKeyCheck = effectiveOptions.body;
    const bodyForPostMessage = effectiveOptions.body;
    return { actualUrl, fetchCallArgs, effectiveOptions, bodyForApiKeyCheck, bodyForPostMessage };
  }

  function handleRequestInput(input, optionsArgument) {
    const actualUrl = input.url;
    const fetchCallArgs = [input, optionsArgument];
    const effectiveOptions = { method: input.method, headers: new Headers(input.headers) };
    let bodyForApiKeyCheck;
    let bodyForPostMessage;

    if (optionsArgument) {
      if (optionsArgument.method) effectiveOptions.method = optionsArgument.method;
      if (optionsArgument.headers) effectiveOptions.headers = new Headers(optionsArgument.headers);
      if ('body' in optionsArgument) {
        bodyForApiKeyCheck = optionsArgument.body;
        bodyForPostMessage = optionsArgument.body;
      } else {
        bodyForApiKeyCheck = undefined;
        bodyForPostMessage = input.body;
      }
    } else {
      bodyForApiKeyCheck = undefined;
      bodyForPostMessage = input.body;
    }
    return { actualUrl, fetchCallArgs, effectiveOptions, bodyForApiKeyCheck, bodyForPostMessage };
  }

  window.fetch = function(input, optionsArgument) {
    let actualUrl;
    let fetchCallArgs;
    let effectiveOptions = {};
    let bodyForApiKeyCheck;
    let bodyForPostMessage;

    if (typeof input === 'string') {
      ({actualUrl, fetchCallArgs, effectiveOptions, bodyForApiKeyCheck, bodyForPostMessage} = handleStringInput(input, optionsArgument));
    } else if (input instanceof Request) {
      ({actualUrl, fetchCallArgs, effectiveOptions, bodyForApiKeyCheck, bodyForPostMessage} = handleRequestInput(input, optionsArgument));
    } else {
      return originalFetch.apply(window, [input, optionsArgument]);
    }

    effectiveOptions.method = effectiveOptions.method || 'GET';
    if (!effectiveOptions.headers) {
      effectiveOptions.headers = new Headers();
    }


    if (typeof actualUrl === 'string' && googleLlmBaseApiUrls.some((url) => actualUrl.startsWith(url))) {
      let apiKeyIsNull = true;

      const regex = new RegExp("models/([^:]+)");
      const modelNameMatch = actualUrl.match(regex);
      const modelName = modelNameMatch ? modelNameMatch[1] : 'unspecified';


      try {
        const urlObject = new URL(actualUrl);  // Use URL object for robust parsing
        const apiKeyParam = urlObject.searchParams.get('key');
        if (apiKeyParam) {
          apiKeyIsNull = false;
        }
      } catch (e) {
        // Continue checks even if URL parsing fails
      }

      if (apiKeyIsNull && effectiveOptions.headers) {
        const h = new Headers(effectiveOptions.headers);
        const apiKeyHeaderValue = h.get('X-API-Key') || h.get('x-api-key');
        if (apiKeyHeaderValue) {
          apiKeyIsNull = false;
          return originalFetch.apply(window, fetchCallArgs);
        }
      }

      if (apiKeyIsNull && effectiveOptions.method && ['POST', 'PUT', 'PATCH'].includes(effectiveOptions.method.toUpperCase()) && typeof bodyForApiKeyCheck === 'string') {
        try {
          const bodyData = JSON.parse(bodyForApiKeyCheck);
          if (bodyData && bodyData.apiKey) {
            apiKeyIsNull = false;
            return originalFetch.apply(window, fetchCallArgs);
          }
        } catch (e) {
          // Ignore JSON parsing errors
        }
      }

      if(apiKeyIsNull) {
        const promiseId = nextPromiseId++;
        const promise = new Promise((resolve) => {
          pendingFetchResolvers[promiseId] = (resolvedResponse) => {
            delete pendingFetchResolvers[promiseId];
            resolve(resolvedResponse);
          };
        });

        let serializedBodyForPostMessage;
        if (typeof bodyForPostMessage === 'string' || bodyForPostMessage == null) {
            serializedBodyForPostMessage = bodyForPostMessage;
        } else if (bodyForPostMessage instanceof ReadableStream) {
            serializedBodyForPostMessage = null;
        } else {
            try {
                serializedBodyForPostMessage = JSON.stringify(bodyForPostMessage);
            } catch (e) {
                serializedBodyForPostMessage = null;
            }
        }

        const messageOptions = {
            method: effectiveOptions.method,
            headers: Object.fromEntries(new Headers(effectiveOptions.headers).entries()),
            body: serializedBodyForPostMessage
        };

        window.parent.postMessage({
          type: 'requestFetch',
          url: actualUrl,
          modelName: modelName,
          options: messageOptions,
          promiseId: promiseId,
        }, '*');

        return promise;
      }
      return originalFetch.apply(window, fetchCallArgs);
    }
    return originalFetch.apply(window, fetchCallArgs);
  };

  window.addEventListener('message', function(event) {
    if (event.data && event.data.type === 'resolveFetch') {
      const { promiseId, response } = event.data;
      if (pendingFetchResolvers[promiseId]) {
        try {
          const reconstructedResponse = new Response(response.body, {
            status: response.status,
            statusText: response.statusText,
            headers: new Headers(response.headers),
          });
          pendingFetchResolvers[promiseId](reconstructedResponse);
        } catch (error) {
          pendingFetchResolvers[promiseId](new Response(null, { status: 500, statusText: "Interceptor Response Reconstruction Error" }));
        }
      }
    }
  });

}))({"textModelName":"gemini-2.5-flash-preview-09-2025","imageModelName":"imagen-4.0-generate-001","imageEditModelName":"gemini-2.5-flash-image-preview","imageTransformModelName":"gemini-3-pro-image-preview-11-2025","videoModelName":"veo-2.0-generate-001","ttsModelName":"gemini-2.5-flash-preview-tts","deprecatedTextModelNames":["gemini-2.0-flash","gemini-2.5-flash-preview-04-17","gemini-2.5-flash-preview-05-20"],"deprecatedImageModelNames":["imagen-3.0-generate-001","imagen-3.0-generate-002"]})</script><script>(function() {
  const originalConsoleLog = console.log;
  const originalConsoleError = console.error;

    /**
   * Normalizes an error event or a promise rejection reason into a structured error object.
   * @param {*} errorEventOrReason The error object or reason.
   * @return {object} Structured error data { message, name, stack }.
   */
  function getErrorObject(errorEventOrReason) {
    if (errorEventOrReason instanceof Error) {
      return {
        message: errorEventOrReason.message,
        name: errorEventOrReason.name,
        stack: errorEventOrReason.stack,
      };
    }
    // Fallback for non-Error objects.
    try {
      return {
        message: JSON.stringify(errorEventOrReason),
        name: 'UnknownErrorType',
        stack: null,
      };
    } catch (e) {
      return {
        message: String(errorEventOrReason),
        name: 'UnknownErrorTypeNonStringifiable',
        stack: null,
      };
    }
  }

  /**
   * Converts an array of arguments (from log/error) into a single string.
   * Handles Error objects specially to include their message and stack.
   * @param {Array<*>} args - Arguments passed to console methods.
   * @return {string} A string representation of the arguments.
   */
  function stringifyArgs(args) {
    return args
      .map((arg) => {
        if (arg instanceof Error) {
          const {message, stack} = arg;
          return `Error: ${message}${stack ? ('\nStack: ' + stack) : ''}`;
        }
        if (typeof arg === 'object' && arg !== null) {
          try {
            return JSON.stringify(arg);
          } catch (error) {
            return '[Circular Object]';
          }
        } else {
          return String(arg);
        }
      })
      .join(' ');
  }

  console.log = function(...args) {
    const logString = stringifyArgs(args);
    window.parent.postMessage({ type: 'log', message: logString }, '*');
    originalConsoleLog.apply(console, args);
  };

  console.error = function(...args) {
    let errorData;
    if (args.length > 0 && args[0] instanceof Error) {
      const err = args[0];
      // If the first arg is an Error, capture its details.
      errorData = {
        type: 'error',
        source: 'CONSOLE_ERROR',
        ...getErrorObject(err),
        rawArgsString: stringifyArgs(args.slice(1)),
        timestamp: new Date().toISOString(),
      };
    } else {
      // If not an Error object, treat all args as a general error message.
      errorData = {
        type: 'error',
        source: 'CONSOLE_ERROR',
        message: stringifyArgs(args),
        name: 'ConsoleLoggedError',
        stack: null,
        timestamp: new Date().toISOString(),
      };
    }
    window.parent.postMessage(errorData, '*');
    originalConsoleError.apply(console, args);
  };

  // Listen for global unhandled synchronous errors.
  window.addEventListener('error', function(event) {
    const errorDetails = event.error ? getErrorObject(event.error) : {
      message: event.message,
      name: 'GlobalError',
      stack: null,
      filename: event.filename,
      lineno: event.lineno,
      colno: event.colno,
    };

    window.parent.postMessage({
      type: 'error',
      source: 'global',
      ...errorDetails,
      message: errorDetails.message || event.message,
      timestamp: new Date().toISOString(),
    }, '*');
  });

  // Listen for unhandled promise rejections (asynchronous errors).
  window.addEventListener('unhandledrejection', function(event) {
    const errorDetails = getErrorObject(event.reason);

    window.parent.postMessage({
      type: 'error',
      source: 'unhandledrejection',
      ...errorDetails,
      message: errorDetails.message || 'Unhandled Promise Rejection',
      timestamp: new Date().toISOString(),
    }, '*');
  });

})();</script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fast Inference PR Walkthrough</title>
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
    <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@400;500&amp;family=Inter:wght@400;600;700;800&amp;display=swap" rel="stylesheet">
    <style>
        :root {
            --space-black: #020617;
            --slate-900: #0f172a;
            --dark-slate: #111827;
            --github-dark: #0d1117;
            --indigo-600: #6366f1;
            --emerald-500: #10b981;
            --border-white: #ffffff14;
            --add-bg: #10b9811f;
            --add-text: #34d399;
            --add-border: #10b981;
            --del-bg: #ef44441f;
            --del-text: #f87171;
            --del-border: #ef4444;
            --header-h: 60px;
            --footer-h: 120px;
            --transition-speed: 0.8s;
            --easing: cubic-bezier(0.65, 0, 0.35, 1);
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            background-color: var(--space-black);
            color: #f8fafc;
            font-family: 'Inter', sans-serif;
            height: 100vh;
            width: 100vw;
            overflow: hidden; /* Scroll Lock */
        }

        /* Fixed UI */
        header {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: var(--header-h);
            padding: 0 40px;
            background: rgba(2, 6, 23, 0.9);
            backdrop-filter: blur(12px);
            border-bottom: 1px solid var(--border-white);
            display: flex;
            align-items: center;
            justify-content: space-between;
            z-index: 1000;
        }

        .header-brand { display: flex; align-items: center; gap: 12px; }
        .badge { background: var(--indigo-600); color: white; font-size: 0.65rem; font-weight: 900; padding: 4px 8px; border-radius: 4px; text-transform: uppercase; }
        .header-title { font-weight: 700; font-size: 0.95rem; color: #cbd5e1; }
        .step-counter { font-family: 'Fira Code', monospace; font-size: 0.8rem; color: #64748b; }

        footer {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            height: var(--footer-h);
            background: var(--space-black);
            border-top: 1px solid var(--border-white);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 1000;
        }

        /* Slide Container */
        #slides-wrapper {
            transition: transform var(--transition-speed) var(--easing);
            height: 100vh;
        }

        .slide {
            height: 100vh;
            width: 100vw;
            display: flex;
            align-items: center;
            justify-content: center;
            padding-top: var(--header-h);
            padding-bottom: var(--footer-h);
        }

        /* Content Box */
        .content-box {
            width: 90%;
            max-width: 1100px;
            /* Height limited to prevent footer overlap */
            height: calc(100vh - var(--header-h) - var(--footer-h) - 40px);
            background: var(--slate-900);
            border: 1px solid var(--border-white);
            border-radius: 20px;
            display: flex;
            flex-direction: column;
            overflow: hidden;
            box-shadow: 0 25px 60px -15px rgba(0, 0, 0, 0.8);
        }

        /* Upper Horizon (Explanation) */
        .pane-explanation {
            height: 42%;
            background: var(--dark-slate);
            border-bottom: 1px solid var(--border-white);
            display: flex;
            flex-direction: column;
        }

        .tab-bar {
            display: flex;
            justify-content: center; /* Centered Tabs */
            gap: 60px;
            padding-top: 10px;
            border-bottom: 1px solid var(--border-white);
        }

        .tab {
            padding: 12px 20px;
            font-size: 0.75rem;
            font-weight: 800;
            text-transform: uppercase;
            letter-spacing: 0.12em;
            cursor: pointer;
            color: #475569;
            transition: color 0.3s ease;
            position: relative;
        }

        .tab.active[data-tab="logic"] { color: var(--indigo-600); }
        .tab.active[data-tab="impact"] { color: var(--emerald-500); }

        .tab::after {
            content: '';
            position: absolute;
            bottom: -1px;
            left: 0;
            width: 100%;
            height: 3px;
            background: transparent;
            transition: background 0.3s;
            border-radius: 3px 3px 0 0;
        }
        .tab.active[data-tab="logic"]::after { background: var(--indigo-600); }
        .tab.active[data-tab="impact"]::after { background: var(--emerald-500); }

        .pane-body {
            flex: 1;
            padding: 32px 60px;
            overflow-y: hidden;
        }

        .insight-panel { display: none; }
        .insight-panel.active { display: block; animation: panelIn 0.4s ease-out; }

        .insight-panel h2 { font-size: 1.5rem; margin-bottom: 12px; font-weight: 800; color: #f1f5f9; letter-spacing: -0.02em; }
        .insight-panel p { line-height: 1.7; color: #94a3b8; font-size: 1.05rem; }

        /* Lower Horizon (Code) */
        .pane-code {
            height: 58%;
            background: var(--github-dark);
            overflow: auto;
            position: relative;
        }

        .code-render {
            padding: 24px 0;
            font-family: 'Fira Code', monospace;
            font-size: 13px;
            line-height: 1.6;
        }

        .diff-line {
            display: flex;
            width: 100%;
            padding: 0 24px;
            white-space: pre-wrap;
            overflow-wrap: anywhere;
            min-height: 1.6em;
        }

        .line-prefix { width: 20px; flex-shrink: 0; opacity: 0.5; user-select: none; }
        .diff-add { background: var(--add-bg); color: var(--add-text) !important; border-left: 4px solid var(--add-border); }
        .diff-del { background: var(--del-bg); color: var(--del-text) !important; border-left: 4px solid var(--del-border); }
        .hunk-header { color: #6e7681; font-style: italic; background: rgba(255,255,255,0.02); }

        /* Control Bar Internals */
        .progress-container { width: 100%; max-width: 480px; margin-bottom: 24px; }
        .progress-track { width: 100%; height: 4px; background: #1e293b; border-radius: 2px; }
        #progress-fill { height: 100%; width: 0%; background: var(--indigo-600); border-radius: 2px; transition: width 0.3s ease; }

        .nav-controls { display: flex; align-items: center; gap: 48px; }
        .btn {
            background: none;
            border: none;
            color: #64748b;
            cursor: pointer;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .btn:hover:not(:disabled) { color: white; transform: scale(1.1); }
        .btn:disabled { opacity: 0.1; cursor: not-allowed; }

        .play-btn {
            width: 48px;
            height: 48px;
            background: var(--indigo-600);
            border-radius: 50%;
            color: white;
            box-shadow: 0 8px 20px -5px rgba(99, 102, 241, 0.5);
            transition: all 0.3s ease;
        }

        .play-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 10px 25px -5px rgba(99, 102, 241, 0.6);
        }

        .play-btn.playing {
            background: var(--emerald-500);
            box-shadow: 0 8px 20px -5px rgba(16, 185, 129, 0.5);
            animation: pulse 2s infinite;
        }

        .play-btn.playing:hover {
            box-shadow: 0 10px 25px -5px rgba(16, 185, 129, 0.6);
        }

        @keyframes pulse {
            0%, 100% { box-shadow: 0 8px 20px -5px rgba(16, 185, 129, 0.5); }
            50% { box-shadow: 0 8px 30px -5px rgba(16, 185, 129, 0.7); }
        }

        @keyframes panelIn { from { opacity: 0; transform: translateX(10px); } to { opacity: 1; transform: translateX(0); } }

        /* Scrollbar aesthetics */
        .pane-body::-webkit-scrollbar, .pane-code::-webkit-scrollbar { width: 5px; }
        .pane-body::-webkit-scrollbar-thumb, .pane-code::-webkit-scrollbar-thumb { background: #334155; border-radius: 10px; }
    </style>
</head>
<body>

    <header>
        <div class="header-brand">
            <span class="badge">Performance</span>
            <span class="header-title">Optimization: Fast Inference RAG</span>
        </div>
        <div class="step-counter" id="step-count-label">STEP 01 // 07</div>
    </header>

    <div id="slides-wrapper" style="transform: translateY(0vh);">
        <!-- Slides Injected via JavaScript -->
    <div class="slide" id="slide-0">
                    <div class="content-box">
                        <div class="pane-explanation">
                            <div class="tab-bar">
                                <div class="tab active" data-tab="logic" onclick="app.setTab(0, 'logic')">Core Logic</div>
                                <div class="tab" data-tab="impact" onclick="app.setTab(0, 'impact')">Impact</div>
                            </div>
                            <div class="pane-body">
                                <div class="insight-panel active" id="logic-0">
                                    <h2>Removal of Query Refinement Step</h2>
                                    <p>Removes the _refine_query method and its invocation. Previously, every query triggered an LLM call to rewrite text before retrieval. Removing this reduces latency by cutting an expensive synchronous LLM round-trip.</p>
                                </div>
                                <div class="insight-panel" id="impact-0">
                                    <h2>Technical Impact</h2>
                                    <p>Drastically reduces the 'time-to-first-token' by removing a pre-retrieval bottleneck.</p>
                                </div>
                            </div>
                        </div>
                        <div class="pane-code">
                            <div class="code-render">
                                <div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         </span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         # Configure LlamaIndex settings</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         Settings._prompt_helper = PromptHelper(context_window=20000)</span></div><div class="diff-line hunk-header"><span class="line-prefix">&nbsp;</span><span>@@ -113,33 +110,12 @@ def __init__(</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         self._refined_query = self._prepare_query()</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         # Setup query engine</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        # self._persist = self._storage_manager.load_persist_dir(persist_dir, collection_name)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         index = self._setup_storage_context(collection_name)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         metadata_filters = self._prepare_metadata_filters(metadata)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         self._init_query_engine(index, metadata_filters)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>    def _refine_query(self, query: str) -&gt; str:</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        # prompt = (</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        #     "Rewrite the following vague or poorly worded query to be clearer and more specific for document retrieval.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        #     f"Original Query: {query}</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>Refined Query:"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        # )</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        prompt = (</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "You are assisting in improving user queries for an enterprise document retrieval system "</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "in the oil and gas domain. The queries may be vague, incomplete, or poorly worded.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "Your task is to rewrite the query to make it clearer and more specific, "</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "while strictly preserving all domain-specific terminology, acronyms, and names (e.g. like 'IBDP').</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "Do NOT expand acronyms unless their expanded form is clearly known in the oil &amp; gas context.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "Do NOT hallucinate or assume meanings outside the domain.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        f"Original Query: {query}</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "Refined Query:"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        )</span></div>
                            </div>
                        </div>
                    </div>
                </div><div class="slide" id="slide-1">
                    <div class="content-box">
                        <div class="pane-explanation">
                            <div class="tab-bar">
                                <div class="tab active" data-tab="logic" onclick="app.setTab(1, 'logic')">Core Logic</div>
                                <div class="tab" data-tab="impact" onclick="app.setTab(1, 'impact')">Impact</div>
                            </div>
                            <div class="pane-body">
                                <div class="insight-panel active" id="logic-1">
                                    <h2>Integration of CompoundQueryRetriever</h2>
                                    <p>Initializes the new CompoundQueryRetriever and injects it into the CitationQueryEngine. This custom retriever handles both decomposition and fusion (reciprocal_rerank) within a single engine setup.</p>
                                </div>
                                <div class="insight-panel" id="impact-1">
                                    <h2>Technical Impact</h2>
                                    <p>Unifies simple and complex query handling into one efficient architecture.</p>
                                </div>
                            </div>
                        </div>
                        <div class="pane-code">
                            <div class="code-render">
                                <div class="diff-line diff-del"><span class="line-prefix">-</span><span></span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        # llm_manager = LLMManager(settings_manager)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         </span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         # Configure LlamaIndex settings</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         Settings._prompt_helper = PromptHelper(context_window=20000)</span></div><div class="diff-line hunk-header"><span class="line-prefix">&nbsp;</span><span>@@ -113,33 +110,12 @@ def __init__(</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         self._refined_query = self._prepare_query()</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         # Setup query engine</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        # self._persist = self._storage_manager.load_persist_dir(persist_dir, collection_name)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         index = self._setup_storage_context(collection_name)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         metadata_filters = self._prepare_metadata_filters(metadata)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>         self._init_query_engine(index, metadata_filters)</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>    def _refine_query(self, query: str) -&gt; str:</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        # prompt = (</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        #     "Rewrite the following vague or poorly worded query to be clearer and more specific for document retrieval.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        #     f"Original Query: {query}</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>Refined Query:"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        # )</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        prompt = (</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "You are assisting in improving user queries for an enterprise document retrieval system "</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "in the oil and gas domain. The queries may be vague, incomplete, or poorly worded.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "Your task is to rewrite the query to make it clearer and more specific, "</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "while strictly preserving all domain-specific terminology, acronyms, and names (e.g. like 'IBDP').</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "Do NOT expand acronyms unless their expanded form is clearly known in the oil &amp; gas context.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        "Do NOT hallucinate or assume meanings outside the domain.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>        f"Original Query: {query}</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span></span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>"</span></div>
                            </div>
                        </div>
                    </div>
                </div><div class="slide" id="slide-2">
                    <div class="content-box">
                        <div class="pane-explanation">
                            <div class="tab-bar">
                                <div class="tab active" data-tab="logic" onclick="app.setTab(2, 'logic')">Core Logic</div>
                                <div class="tab" data-tab="impact" onclick="app.setTab(2, 'impact')">Impact</div>
                            </div>
                            <div class="pane-body">
                                <div class="insight-panel active" id="logic-2">
                                    <h2>Unified Execution Path</h2>
                                    <p>Comments out the explicit branching logic for compound queries. The pipeline now uses a single flow (generate_answer) for all query types, relying on the retriever to handle complexity internally.</p>
                                </div>
                                <div class="insight-panel" id="impact-2">
                                    <h2>Technical Impact</h2>
                                    <p>Simplifies maintenance and eliminates redundant code paths.</p>
                                </div>
                            </div>
                        </div>
                        <div class="pane-code">
                            <div class="code-render">
                                <div class="diff-line diff-add"><span class="line-prefix">+</span><span>                llm=self._model_manager.llm,</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>                num_queries=4,  # Generate up to 4 sub-queries</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>                similarity_top_k=self._config("RAG_SIMILARITY_TOP_K"),</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>                mode="reciprocal_rerank", # Re-rank results from all sub-queries</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            )</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>             self.query_engine = CitationQueryEngine.from_args(</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 index,</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>                retriever=retriever,</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 embed_model=self._model_manager.embed_model,</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 chat_mode="context",</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 citation_chunk_size=self._config("RAG_CITATION_CHUNK_SIZE"),</span></div><div class="diff-line hunk-header"><span class="line-prefix">&nbsp;</span><span>@@ -325,30 +287,32 @@ def generate_answer(self) -&gt; Generator[str, None, None]:</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 yield from self._handle_greeting()</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 return</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>            elif self._is_compound_query(self._refined_query):</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                updated_subq_answers, sources_text,ordered_docs, ordered_nodes = self._handle_compound_query_v2()</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                response = self._chat_synthesize_subanswers_v2(self._refined_query, updated_subq_answers, sources_text)</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                answer = ""</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                if response:</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                    for chunk_json in self.response_generator(response.text):</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            chunk = json.loads(chunk_json)["text"]</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            if chunk != "Empty Response":</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                                answer += chunk</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            yield chunk_json</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                else:</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                    logger.warning("No sub queries/response found")</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                    if self._is_web_search != "True":</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                        yield json.dumps({</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            "response_id": str(uuid.uuid4()),</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            "type": "answer",</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            "text": "No relevant contexts retrieved",</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                        })</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                contexts, answer = self._process_contexts(answer, ordered_nodes, ordered_docs)</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                yield from self._yield_context_answer(contexts,answer)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            # elif self._is_compound_query(self._refined_query):</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #     updated_subq_answers, sources_text,ordered_docs, ordered_nodes = self._handle_compound_query_v2()</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #     response = self._chat_synthesize_subanswers_v2(self._refined_query, updated_subq_answers, sources_text)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #     answer = ""</span></div>
                            </div>
                        </div>
                    </div>
                </div><div class="slide" id="slide-3">
                    <div class="content-box">
                        <div class="pane-explanation">
                            <div class="tab-bar">
                                <div class="tab active" data-tab="logic" onclick="app.setTab(3, 'logic')">Core Logic</div>
                                <div class="tab" data-tab="impact" onclick="app.setTab(3, 'impact')">Impact</div>
                            </div>
                            <div class="pane-body">
                                <div class="insight-panel active" id="logic-3">
                                    <h2>Simplified Compound Query Detection</h2>
                                    <p>Refactors _is_compound_query to use a centralized prompt asset instead of inline string literals.</p>
                                </div>
                                <div class="insight-panel" id="impact-3">
                                    <h2>Technical Impact</h2>
                                    <p>Improves prompt management and separation of concerns.</p>
                                </div>
                            </div>
                        </div>
                        <div class="pane-code">
                            <div class="code-render">
                                <div class="diff-line diff-add"><span class="line-prefix">+</span><span>            )</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>             self.query_engine = CitationQueryEngine.from_args(</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 index,</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>                retriever=retriever,</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 embed_model=self._model_manager.embed_model,</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 chat_mode="context",</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 citation_chunk_size=self._config("RAG_CITATION_CHUNK_SIZE"),</span></div><div class="diff-line hunk-header"><span class="line-prefix">&nbsp;</span><span>@@ -325,30 +287,32 @@ def generate_answer(self) -&gt; Generator[str, None, None]:</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 yield from self._handle_greeting()</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 return</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>            elif self._is_compound_query(self._refined_query):</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                updated_subq_answers, sources_text,ordered_docs, ordered_nodes = self._handle_compound_query_v2()</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                response = self._chat_synthesize_subanswers_v2(self._refined_query, updated_subq_answers, sources_text)</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                answer = ""</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                if response:</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                    for chunk_json in self.response_generator(response.text):</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            chunk = json.loads(chunk_json)["text"]</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            if chunk != "Empty Response":</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                                answer += chunk</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            yield chunk_json</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                else:</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                    logger.warning("No sub queries/response found")</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                    if self._is_web_search != "True":</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                        yield json.dumps({</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            "response_id": str(uuid.uuid4()),</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            "type": "answer",</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                            "text": "No relevant contexts retrieved",</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                        })</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                contexts, answer = self._process_contexts(answer, ordered_nodes, ordered_docs)</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>                yield from self._yield_context_answer(contexts,answer)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            # elif self._is_compound_query(self._refined_query):</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #     updated_subq_answers, sources_text,ordered_docs, ordered_nodes = self._handle_compound_query_v2()</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #     response = self._chat_synthesize_subanswers_v2(self._refined_query, updated_subq_answers, sources_text)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #     answer = ""</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #     if response:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #         for chunk_json in self.response_generator(response.text):</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #                 chunk = json.loads(chunk_json)["text"]</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            #                 if chunk != "Empty Response":</span></div>
                            </div>
                        </div>
                    </div>
                </div><div class="slide" id="slide-4">
                    <div class="content-box">
                        <div class="pane-explanation">
                            <div class="tab-bar">
                                <div class="tab active" data-tab="logic" onclick="app.setTab(4, 'logic')">Core Logic</div>
                                <div class="tab" data-tab="impact" onclick="app.setTab(4, 'impact')">Impact</div>
                            </div>
                            <div class="pane-body">
                                <div class="insight-panel active" id="logic-4">
                                    <h2>New Compound Query Retriever</h2>
                                    <p>Introduces the CompoundQueryRetriever class. It encapsulates detection, decomposition, and result fusion logic.</p>
                                </div>
                                <div class="insight-panel" id="impact-4">
                                    <h2>Technical Impact</h2>
                                    <p>Moves logic into a specialized component for better scalability.</p>
                                </div>
                            </div>
                        </div>
                        <div class="pane-code">
                            <div class="code-render">
                                <div class="diff-line"><span class="line-prefix">&nbsp;</span><span>--- /dev/null</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>+++ b/core/retrieval_api/retrievers/compound_retriever.py</span></div><div class="diff-line hunk-header"><span class="line-prefix">&nbsp;</span><span>@@ -0,0 +1,78 @@</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>import logging</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>from enum import Enum</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>import json</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>from typing import Dict, List, Optional, Tuple, cast</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>from llama_index.core.retrievers import QueryFusionRetriever</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>from llama_index.core.schema import QueryBundle, NodeWithScore</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span></span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>logger = logging.getLogger(__name__)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span></span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>class CompoundQueryRetriever(QueryFusionRetriever):</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>    def __init__(self, compound_query_classify_prompt: str, *args, **kwargs):</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        super().__init__(*args, **kwargs)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        self.compound_query_classify_prompt = compound_query_classify_prompt</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span></span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>    def _is_compound_query(self, query: str) -&gt; bool:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        is_compound_prompt = self.compound_query_classify_prompt.format(query=query)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        resp = self._llm.complete(is_compound_prompt)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        return "yes" in resp.text.lower()</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span></span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>    def _parse_subqueries(self, llm_output: str) -&gt; list[str]:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        try:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            return json.loads(llm_output)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        except json.JSONDecodeError:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            raise ValueError(f"Subquery output is not valid JSON:</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>{llm_output}")</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span></span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>    def _decompose_query(self, query: str) -&gt; List[str]:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        try:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            sub_query_gen_prompt = self.query_gen_prompt.format(query =query)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            response = self._llm.complete(sub_query_gen_prompt)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            subqueries = self._parse_subqueries(response.text)</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            if isinstance(subqueries, list) and all(isinstance(q, str) for q in subqueries):</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>                return subqueries</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            else:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>                raise ValueError("Invalid format: not a list of strings")</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>        except json.JSONDecodeError as e:</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            raise ValueError(f"Subquery response not valid JSON: {e}")</span></div>
                            </div>
                        </div>
                    </div>
                </div><div class="slide" id="slide-5">
                    <div class="content-box">
                        <div class="pane-explanation">
                            <div class="tab-bar">
                                <div class="tab active" data-tab="logic" onclick="app.setTab(5, 'logic')">Core Logic</div>
                                <div class="tab" data-tab="impact" onclick="app.setTab(5, 'impact')">Impact</div>
                            </div>
                            <div class="pane-body">
                                <div class="insight-panel active" id="logic-5">
                                    <h2>Optimization of Chat Service</h2>
                                    <p>Removes the synchronous chat history load from the request loop, reducing I/O overhead.</p>
                                </div>
                                <div class="insight-panel" id="impact-5">
                                    <h2>Technical Impact</h2>
                                    <p>Contributes to overall inference speed by cleaning up the service-level hot path.</p>
                                </div>
                            </div>
                        </div>
                        <div class="pane-code">
                            <div class="code-render">
                                <div class="diff-line"><span class="line-prefix">&nbsp;</span><span>a/core/retrieval_api/services/chat_service.py b/core/retrieval_api/services/chat_service.py</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>index 9f5ccc7..dad918c 100644</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>--- a/core/retrieval_api/services/chat_service.py</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>+++ b/core/retrieval_api/services/chat_service.py</span></div><div class="diff-line hunk-header"><span class="line-prefix">&nbsp;</span><span>@@ -50,10 +50,6 @@ async def process_rag_chat(self, request: ChatRequest) -&gt; StreamingResponse:</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>             start_time = time.perf_counter()</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>             logger.info(f"Processing RAG chat request for chat_id: {request.chat_id}")</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>             </span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>            # Load chat history</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>            self._storage.load_chat_history(request.chat_id)</span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span></span></div><div class="diff-line diff-del"><span class="line-prefix">-</span><span>            </span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>             # Create Generate instance</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>             generate = Generate(</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 config=self._settings.get_setting,</span></div><div class="diff-line hunk-header"><span class="line-prefix">&nbsp;</span><span>@@ -91,6 +87,7 @@ async def process_rag_chat(self, request: ChatRequest) -&gt; StreamingResponse:</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 }</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 yield json.dumps(chunk_data)  # Yield the modified JSON chunk</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>                 # yield chunk</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>            logger.info(f"Time taken for response generation: {time.perf_counter() - start_time}")</span></div>
                            </div>
                        </div>
                    </div>
                </div><div class="slide" id="slide-6">
                    <div class="content-box">
                        <div class="pane-explanation">
                            <div class="tab-bar">
                                <div class="tab active" data-tab="logic" onclick="app.setTab(6, 'logic')">Core Logic</div>
                                <div class="tab" data-tab="impact" onclick="app.setTab(6, 'impact')">Impact</div>
                            </div>
                            <div class="pane-body">
                                <div class="insight-panel active" id="logic-6">
                                    <h2>Output Formatting Constraint</h2>
                                    <p>Adds a prompt instruction to suppress 'Document Title' information in final answers.</p>
                                </div>
                                <div class="insight-panel" id="impact-6">
                                    <h2>Technical Impact</h2>
                                    <p>Ensures cleaner, more professional response formatting for the end user.</p>
                                </div>
                            </div>
                        </div>
                        <div class="pane-code">
                            <div class="code-render">
                                <div class="diff-line"><span class="line-prefix">&nbsp;</span><span>a/core/retrieval_api/prompts/qa_template.prompt b/core/retrieval_api/prompts/qa_template.prompt</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>index 2f8ba96..f228e6b 100644</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>--- a/core/retrieval_api/prompts/qa_template.prompt</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span>+++ b/core/retrieval_api/prompts/qa_template.prompt</span></div><div class="diff-line hunk-header"><span class="line-prefix">&nbsp;</span><span>@@ -9,6 +9,7 @@ Follow these guidelines to incorporate markdown formatting wherever applicable:</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> 7. Convert any table into markdown table format using | for columns and - for the header row separator</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> 8. Add horizontal rules where appropriate. Preserve line breaks and paragraphs</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> 9. Do not convert citations or references such as [1] into footnotes in markdown format i.e. [^1]</span></div><div class="diff-line diff-add"><span class="line-prefix">+</span><span>10. Do not mention Document Title information in the answer</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> </span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> Ensure that the answer is generated in MLA 9th edition style format.</span></div><div class="diff-line"><span class="line-prefix">&nbsp;</span><span> Now it's your turn. Below are several numbered sources of information:</span></div>
                            </div>
                        </div>
                    </div>
                </div></div>

    <footer>
        <div class="progress-container">
            <div class="progress-track"><div id="progress-fill" style="width: 14.2857%;"></div></div>
        </div>
        <div class="nav-controls">
            <button class="btn" id="prev-btn" onclick="app.prev()" disabled="">
                <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round"><path d="m15 18-6-6 6-6"></path></svg>
            </button>
            <button class="btn play-btn" id="play-btn" onclick="app.togglePlay()">
                <div id="play-icon">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M8 5v14l11-7z"></path></svg>
                </div>
            </button>
            <button class="btn" id="next-btn" onclick="app.next()">
                <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round"><path d="m9 18 6-6-9-6"></path></svg>
            </button>
        </div>
    </footer>

    <script>
        const PR_RAW_DIFF = `diff --git a/core/retrieval_api/generate.py b/core/retrieval_api/generate.py
index 2721a69..e081e56 100644
--- a/core/retrieval_api/generate.py
+++ b/core/retrieval_api/generate.py
@@ -17,7 +17,7 @@
 from tavily import TavilyClient
 from llama_index.core import StorageContext, Settings, load_index_from_storage,PromptHelper,VectorStoreIndex
 from llama_index.core.schema import QueryBundle, Node
-from llama_index.core.query_engine import CitationQueryEngine 
+from llama_index.core.query_engine import CitationQueryEngine
 
 from llama_index.core.tools import QueryEngineTool, ToolMetadata
 from llama_index.core.query_engine import SubQuestionQueryEngine
@@ -40,6 +40,7 @@
 from .managers.storage_manager import StorageManager
 from .managers.llm_manager import LLMManager
 from .managers.prompt_manager import PromptManager
+from .retrievers.compound_retriever import CompoundQueryRetriever
 
 warnings.filterwarnings("ignore")
 
@@ -87,12 +88,8 @@ def __init__(
         self._cohere_api_key = self._secret("COHERE_API_KEY")
 
         logger.info(f"Initializing Generate for category: {category_name}")
-
         self._prompts = PromptManager.load_prompts(self._config)
-
         self._model_manager = self._llm_manager
-
-        # llm_manager = LLMManager(settings_manager)
         
         # Configure LlamaIndex settings
         Settings._prompt_helper = PromptHelper(context_window=20000)
@@ -113,33 +110,12 @@ def __init__(
         self._refined_query = self._prepare_query()
 
         # Setup query engine
-        # self._persist = self._storage_manager.load_persist_dir(persist_dir, collection_name)
         index = self._setup_storage_context(collection_name)
         metadata_filters = self._prepare_metadata_filters(metadata)
         self._init_query_engine(index, metadata_filters)
 
-    def _refine_query(self, query: str) -> str:
-        # prompt = (
-        #     "Rewrite the following vague or poorly worded query to be clearer and more specific for document retrieval.\n\n"
-        #     f"Original Query: {query}\n\nRefined Query:"
-        # )
-        prompt = (
-        "You are assisting in improving user queries for an enterprise document retrieval system "
-        "in the oil and gas domain. The queries may be vague, incomplete, or poorly worded.\n\n"
-        "Your task is to rewrite the query to make it clearer and more specific, "
-        "while strictly preserving all domain-specific terminology, acronyms, and names (e.g. like 'IBDP').\n\n"
-        "Do NOT expand acronyms unless their expanded form is clearly known in the oil & gas context.\n"
-        "Do NOT hallucinate or assume meanings outside the domain.\n\n"
-        f"Original Query: {query}\n\n"
-        "Refined Query:"
-        )
-        refined = self._model_manager.llm.complete(prompt)
-        logger.debug(f"refined_query, {refined}")
-        return refined.text.strip()
-
     def _prepare_query(self) -> str:
         """Prepare the refined query with chat history."""
-        # self._query = self._refine_query(self._query)
         if self._storage_manager.chat_hist is not None:
             return f"<|CHAT HISTORY|>: {self._storage_manager.chat_hist}\n\n<|QUERY|>: {self._query}"
         return f"<|QUERY|>: {self._query}"
@@ -169,17 +145,6 @@ def _setup_storage_context(self, collection_name: str) -> StorageContext:
             collections = client.get_collections()
             logger.debug(f"collections in vector db: {collections}")
 
-            # storage_context = StorageContext.from_defaults(
-            #     persist_dir=self._persist, vector_store=vector_store
-            # )
-
-            # storage_context = StorageContext.from_defaults(
-            #     vector_store=vector_store
-            # )
-            # index = load_index_from_storage(storage_context)
-
-            # logger.info("storage context created")
-
             index = VectorStoreIndex.from_vector_store(vector_store=vector_store)
             logger.info("index created")
             
@@ -203,24 +168,7 @@ def _init_query_engine(self, index, metadata_filters: Optional[List[MetadataFilt
                 similarity_cutoff=self._config("RAG_SIMILARITY_CUTOFF")
             )
 
-            prompt_template = PromptTemplate(
-                """You are given a query and a list of document snippets.
-            Your job is to identify which snippets are the most relevant to the query.
-
-            Query: {query_str}
-
-            Snippets:
-            {context_str}
-
-            Instructions:
-            Return your answers in this numbered format:
-            1: Relevant
-            2: Not Relevant
-            ...
-
-            Only respond in this format. Do not add any explanations."""
-            )
-
+            ## TODO: to enable this functionality, checkout 4428f82a5292f4f7d1600864b91a476116fddfc6
             # rerank = LLMRerank(
             #     top_n=self._config("RAG_RERANKED_TOP_N"),
             #     llm=self._model_manager.llm,
@@ -239,9 +187,23 @@ def _init_query_engine(self, index, metadata_filters: Optional[List[MetadataFilt
             citation_refine_template=PromptTemplate(
                     self._prompts.citation_template + self._prompts.refine_template
                 )
+            
+            base_retriever = index.as_retriever(
+                similarity_top_k=self._config("RAG_SIMILARITY_TOP_K")
+            )
+            retriever = CompoundQueryRetriever(
+                compound_query_classify_prompt=self._prompts.is_compound_prompt,
+                query_gen_prompt=self._prompts.chat_subquery,
+                retrievers=[base_retriever],
+                llm=self._model_manager.llm,
+                num_queries=4,  # Generate up to 4 sub-queries
+                similarity_top_k=self._config("RAG_SIMILARITY_TOP_K"),
+                mode="reciprocal_rerank", # Re-rank results from all sub-queries
+            )
 
             self.query_engine = CitationQueryEngine.from_args(
                 index,
+                retriever=retriever,
                 embed_model=self._model_manager.embed_model,
                 chat_mode="context",
                 citation_chunk_size=self._config("RAG_CITATION_CHUNK_SIZE"),
@@ -325,30 +287,32 @@ def generate_answer(self) -> Generator[str, None, None]:
                 yield from self._handle_greeting()
                 return
 
-            elif self._is_compound_query(self._refined_query):
-                updated_subq_answers, sources_text,ordered_docs, ordered_nodes = self._handle_compound_query_v2()
-                response = self._chat_synthesize_subanswers_v2(self._refined_query, updated_subq_answers, sources_text)
-                answer = ""
-                if response:
-                    for chunk_json in self.response_generator(response.text):
-                            chunk = json.loads(chunk_json)["text"]
-                            if chunk != "Empty Response":
-                                answer += chunk
-                            yield chunk_json
-                else:
-                    logger.warning("No sub queries/response found")
-                    if self._is_web_search != "True":
-                        yield json.dumps({
-                            "response_id": str(uuid.uuid4()),
-                            "type": "answer",
-                            "text": "No relevant contexts retrieved",
-                        })
-                contexts, answer = self._process_contexts(answer, ordered_nodes, ordered_docs)
-                yield from self._yield_context_answer(contexts,answer)
+            # elif self._is_compound_query(self._refined_query):
+            #     updated_subq_answers, sources_text,ordered_docs, ordered_nodes = self._handle_compound_query_v2()
+            #     response = self._chat_synthesize_subanswers_v2(self._refined_query, updated_subq_answers, sources_text)
+            #     answer = ""
+            #     if response:
+            #         for chunk_json in self.response_generator(response.text):
+            #                 chunk = json.loads(chunk_json)["text"]
+            #                 if chunk != "Empty Response":
+            #                     answer += chunk
+            #                 yield chunk_json
+            #     else:
+            #         logger.warning("No sub queries/response found")
+            #         if self._is_web_search != "True":
+            #             yield json.dumps({
+            #                 "response_id": str(uuid.uuid4()),
+            #                 "type": "answer",
+            #                 "text": "No relevant contexts retrieved",
+            #             })
+            #     contexts, answer = self._process_contexts(answer, ordered_nodes, ordered_docs)
+            #     yield from self._yield_context_answer(contexts,answer)
                 
             else:
                 # Retrieving docs
+                start_time = time.perf_counter()
                 retrieved_docs = self._retrieve_documents()
+                logger.info(f"Time taken for document retrieval: {time.perf_counter() - start_time}")
                 #logger.info(f"has_valid_docs, {self._has_valid_docs(retrieved_docs)}")
                 if not self._has_valid_docs(retrieved_docs):
                     if self._is_web_search:
@@ -360,14 +324,15 @@ def generate_answer(self) -> Generator[str, None, None]:
 
                 # Generate response
                 logger.info("Generating response...")
-                response = self.query_engine.query(self._refined_query)
+                # response = self.query_engine.query(self._refined_query)
+                response = self.query_engine.synthesize(
+                    query_bundle = QueryBundle(query_str=self._refined_query),
+                    nodes = retrieved_docs,
+                )
 
                 # yield generated response
                 answer = ""
                 if response:
-                    # logger.info("XXXXX yielding from response gen")
-                    # answer = self._get_answer_from_response(response)
-                    # yield from self._yield_response_gen(response)
                     for text in response.response_gen:
                         if text != "Empty Response":
                             answer += text
@@ -1017,23 +982,7 @@ def response_generator(self, response_str, chunk_size=50):
             })
 
     def _is_compound_query(self, query: str) -> bool:
-        # prompt = (
-        #     "Does the following query contain multiple questions or sub-intents? "
-        #     "Answer with a single word: 'Yes' or 'No'.\n\nQuery: "
-        #     + query
-        # )
-        prompt = (
-            "You are an expert at understanding natural language queries.\n"
-            "Your task is to determine whether the following query is **compound**"
-            "if it Asks for more than one distinct piece of information.\n"
-            "Contains multiple sub-intents or investigative directions\n"
-            "Requires multiple reasoning or action steps to answer\n"
-            "if asks about multiple time frames or entities\n"
-            "Respond with a **single word** only: \`'Yes'\` if the query contains multiple questions or sub-intents, "
-            "or \`'No'\` if it is a single, focused question.\n\n"
-            f"Query: {query}\n\nAnswer:"
-        )
-        is_compound_prompt = self._prompts.is_compound_prompt.format(query =query)
+        is_compound_prompt = self._prompts.is_compound_prompt.format(query=query)
         resp = self._model_manager.llm.complete(is_compound_prompt)
         return "yes" in resp.text.lower()
     
diff --git a/core/retrieval_api/prompts/qa_template.prompt b/core/retrieval_api/prompts/qa_template.prompt
index 2f8ba96..f228e6b 100644
--- a/core/retrieval_api/prompts/qa_template.prompt
+++ b/core/retrieval_api/prompts/qa_template.prompt
@@ -9,6 +9,7 @@ Follow these guidelines to incorporate markdown formatting wherever applicable:
 7. Convert any table into markdown table format using | for columns and - for the header row separator
 8. Add horizontal rules where appropriate. Preserve line breaks and paragraphs
 9. Do not convert citations or references such as [1] into footnotes in markdown format i.e. [^1]
+10. Do not mention Document Title information in the answer
 
 Ensure that the answer is generated in MLA 9th edition style format.
 Now it's your turn. Below are several numbered sources of information:
diff --git a/core/retrieval_api/retrievers/compound_retriever.py b/core/retrieval_api/retrievers/compound_retriever.py
new file mode 100644
index 0000000..cb37678
--- /dev/null
+++ b/core/retrieval_api/retrievers/compound_retriever.py
@@ -0,0 +1,78 @@
+import logging
+from enum import Enum
+import json
+from typing import Dict, List, Optional, Tuple, cast
+from llama_index.core.retrievers import QueryFusionRetriever
+from llama_index.core.schema import QueryBundle, NodeWithScore
+
+logger = logging.getLogger(__name__)
+
+class CompoundQueryRetriever(QueryFusionRetriever):
+    def __init__(self, compound_query_classify_prompt: str, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.compound_query_classify_prompt = compound_query_classify_prompt
+
+    def _is_compound_query(self, query: str) -> bool:
+        is_compound_prompt = self.compound_query_classify_prompt.format(query=query)
+        resp = self._llm.complete(is_compound_prompt)
+        return "yes" in resp.text.lower()
+
+    def _parse_subqueries(self, llm_output: str) -> list[str]:
+        try:
+            return json.loads(llm_output)
+        except json.JSONDecodeError:
+            raise ValueError(f"Subquery output is not valid JSON:\n{llm_output}")
+
+    def _decompose_query(self, query: str) -> List[str]:
+        try:
+            sub_query_gen_prompt = self.query_gen_prompt.format(query =query)
+            response = self._llm.complete(sub_query_gen_prompt)
+            subqueries = self._parse_subqueries(response.text)
+            if isinstance(subqueries, list) and all(isinstance(q, str) for q in subqueries):
+                return subqueries
+            else:
+                raise ValueError("Invalid format: not a list of strings")
+        except json.JSONDecodeError as e:
+            raise ValueError(f"Subquery response not valid JSON: {e}")
+
+    def _get_queries(self, original_query: str) -> List[QueryBundle]:
+        subqueries = []
+        if self._is_compound_query(original_query):
+            subqueries = self._decompose_query(original_query)
+        logger.info(f"Subqueries: {subqueries}")
+        return [QueryBundle(q) for q in subqueries[: self.num_queries - 1]]
+diff --git a/core/retrieval_api/services/chat_service.py b/core/retrieval_api/services/chat_service.py
index 9f5ccc7..dad918c 100644
--- a/core/retrieval_api/services/chat_service.py
+++ b/core/retrieval_api/services/chat_service.py
@@ -50,10 +50,6 @@ async def process_rag_chat(self, request: ChatRequest) -> StreamingResponse:
             start_time = time.perf_counter()
             logger.info(f"Processing RAG chat request for chat_id: {request.chat_id}")
             
-            # Load chat history
-            self._storage.load_chat_history(request.chat_id)
-
-            
             # Create Generate instance
             generate = Generate(
                 config=self._settings.get_setting,
@@ -91,6 +87,7 @@ async def process_rag_chat(self, request: ChatRequest) -> StreamingResponse:
                 }
                 yield json.dumps(chunk_data)  # Yield the modified JSON chunk
                 # yield chunk
+            logger.info(f"Time taken for response generation: {time.perf_counter() - start_time}")`;

        const WALKTHROUGH_JSON = [
            {
                "id": 1,
                "title": "Removal of Query Refinement Step",
                "description": "Removes the _refine_query method and its invocation. Previously, every query triggered an LLM call to rewrite text before retrieval. Removing this reduces latency by cutting an expensive synchronous LLM round-trip.",
                "impact": "Drastically reduces the 'time-to-first-token' by removing a pre-retrieval bottleneck.",
                "file_path": "core/retrieval_api/generate.py",
                "related_component": "_refine_query"
            },
            {
                "id": 2,
                "title": "Integration of CompoundQueryRetriever",
                "description": "Initializes the new CompoundQueryRetriever and injects it into the CitationQueryEngine. This custom retriever handles both decomposition and fusion (reciprocal_rerank) within a single engine setup.",
                "impact": "Unifies simple and complex query handling into one efficient architecture.",
                "file_path": "core/retrieval_api/generate.py",
                "related_component": "_init_query_engine"
            },
            {
                "id": 3,
                "title": "Unified Execution Path",
                "description": "Comments out the explicit branching logic for compound queries. The pipeline now uses a single flow (generate_answer) for all query types, relying on the retriever to handle complexity internally.",
                "impact": "Simplifies maintenance and eliminates redundant code paths.",
                "file_path": "core/retrieval_api/generate.py",
                "related_component": "generate_answer"
            },
            {
                "id": 4,
                "title": "Simplified Compound Query Detection",
                "description": "Refactors _is_compound_query to use a centralized prompt asset instead of inline string literals.",
                "impact": "Improves prompt management and separation of concerns.",
                "file_path": "core/retrieval_api/generate.py",
                "related_component": "_is_compound_query"
            },
            {
                "id": 5,
                "title": "New Compound Query Retriever",
                "description": "Introduces the CompoundQueryRetriever class. It encapsulates detection, decomposition, and result fusion logic.",
                "impact": "Moves logic into a specialized component for better scalability.",
                "file_path": "core/retrieval_api/retrievers/compound_retriever.py",
                "related_component": "CompoundQueryRetriever"
            },
            {
                "id": 6,
                "title": "Optimization of Chat Service",
                "description": "Removes the synchronous chat history load from the request loop, reducing I/O overhead.",
                "impact": "Contributes to overall inference speed by cleaning up the service-level hot path.",
                "file_path": "core/retrieval_api/services/chat_service.py",
                "related_component": "process_rag_chat"
            },
            {
                "id": 7,
                "title": "Output Formatting Constraint",
                "description": "Adds a prompt instruction to suppress 'Document Title' information in final answers.",
                "impact": "Ensures cleaner, more professional response formatting for the end user.",
                "file_path": "core/retrieval_api/prompts/qa_template.prompt",
                "related_component": "qa_template"
            }
        ];

        const VOICE_OVER_SCRIPTS = [
            {
                "label": "step-1",
                "title": "Removal of Query Refinement Step",
                "voice_over_text": "Let's kick things off with a major latency win. We've removed the legacy query refinement step. Previously, we were hitting an LLM just to rewrite the user's question before even starting retrieval. Cutting this out saves us a full synchronous round-trip, bringing us much closer to that 'fast inference' goal."
            },
            {
                "label": "step-2",
                "title": "Integration of CompoundQueryRetriever",
                "voice_over_text": "Next up, we're looking at the architecture of the retrieval engine itself. We've injected the new CompoundQueryRetriever directly into the main Citation engine. This is a smart component that handles both query decomposition and result fusion in one place, keeping our engine setup clean and predictable."
            },
            {
                "label": "step-3",
                "title": "Unified Execution Path",
                "voice_over_text": "Notice how we've commented out the branching logic here. Instead of having separate tracks for simple and complex queries, we now have a single, unified execution path. By letting the retriever handle the complexity internally, we've eliminated a lot of redundant code and potential edge-case bugs."
            },
            {
                "label": "step-4",
                "title": "Simplified Compound Query Detection",
                "voice_over_text": "We're also cleaning up our internal state management. The compound query detection now pulls its instructions from a centralized prompt manager. It's a small refactor, but it makes it much easier to tune our classification logic without digging through the main API files."
            },
            {
                "label": "step-5",
                "title": "New Compound Query Retriever",
                "voice_over_text": "Here's the new class itself. It inherits from LlamaIndex's FusionRetriever but adds our specialized decomposition logic. By moving this complexity out of the main 'Generate' class, we've created a modular component that we can test and optimize in isolation."
            },
            {
                "label": "step-6",
                "title": "Optimization of Chat Service",
                "voice_over_text": "On the service level, we've removed the synchronous history load. We found that loading chat history in this loop was creating unnecessary I/O wait times. Removing this overhead helps us maintain high throughput as the system scales."
            },
            {
                "label": "step-7",
                "title": "Output Formatting Constraint",
                "voice_over_text": "Finally, we're improving the polish of our answers. We've added a strict formatting constraint to the QA prompt to prevent internal document titles from leaking into the final text. This keeps the response focused purely on technical content, making it much more professional."
            }
        ];

        class App {
            constructor() {
                this.currentStep = 0;
                this.currentTab = 'logic'; // 'logic' or 'impact'
                this.isPlaying = false;
                this.diffFiles = this.parseDiff(PR_RAW_DIFF);
                this.audioElements = [];
                this.currentAudio = null;
                this.init();
                this.initAudio();
            }

            initAudio() {
                // Create audio elements for each slide
                for (let i = 0; i < WALKTHROUGH_JSON.length; i++) {
                    const audio = new Audio(`slide-${i}.mp3`);
                    audio.preload = 'auto';
                    audio.addEventListener('ended', () => this.onAudioEnded());
                    audio.addEventListener('error', (e) => {
                        console.warn(`Audio slide-${i}.mp3 failed to load`, e);
                    });
                    this.audioElements.push(audio);
                }
            }

            onAudioEnded() {
                if (!this.isPlaying) return;

                // Move to next slide when audio ends
                if (this.currentStep < WALKTHROUGH_JSON.length - 1) {
                    this.currentStep++;
                    this.updateUI();
                    this.playCurrentAudio();
                } else {
                    // Last slide audio ended, stop playing
                    this.togglePlay();
                }
            }

            playCurrentAudio() {
                // Stop any currently playing audio
                this.stopAllAudio();

                if (this.audioElements[this.currentStep]) {
                    this.currentAudio = this.audioElements[this.currentStep];
                    this.currentAudio.currentTime = 0;
                    this.currentAudio.play().catch(e => {
                        console.warn('Audio playback failed:', e);
                    });
                }
            }

            pauseCurrentAudio() {
                if (this.currentAudio) {
                    this.currentAudio.pause();
                }
            }

            resumeCurrentAudio() {
                if (this.currentAudio) {
                    this.currentAudio.play().catch(e => {
                        console.warn('Audio resume failed:', e);
                    });
                }
            }

            stopAllAudio() {
                this.audioElements.forEach(audio => {
                    audio.pause();
                    audio.currentTime = 0;
                });
            }

            parseDiff(raw) {
                const parts = raw.split('diff --git');
                const map = {};
                parts.forEach(p => {
                    if (!p.trim()) return;
                    const pathMatch = p.match(/a\/(.+?) b\//);
                    if (pathMatch) {
                        const path = pathMatch[1];
                        map[path] = p.trim();
                    }
                });
                return map;
            }

            init() {
                const wrapper = document.getElementById('slides-wrapper');
                WALKTHROUGH_JSON.forEach((step, idx) => {
                    wrapper.appendChild(this.createSlide(step, idx));
                });
                this.updateUI();
            }

            createSlide(step, idx) {
                const slide = document.createElement('div');
                slide.className = 'slide';
                slide.id = `slide-${idx}`;

                const diffText = this.diffFiles[step.file_path] || "--- File not found in diff ---";
                const hunk = this.isolateHunk(diffText, step.related_component);
                slide.innerHTML = `
                    <div class="content-box">
                        <div class="pane-explanation">
                            <div class="tab-bar">
                                <div class="tab active" data-tab="logic" onclick="app.setTab(${idx}, 'logic')">Core Logic</div>
                                <div class="tab" data-tab="impact" onclick="app.setTab(${idx}, 'impact')">Impact</div>
                            </div>
                            <div class="pane-body">
                                <div class="insight-panel active" id="logic-${idx}">
                                    <h2>${step.title}</h2>
                                    <p>${step.description}</p>
                                </div>
                                <div class="insight-panel" id="impact-${idx}">
                                    <h2>Technical Impact</h2>
                                    <p>${step.impact}</p>
                                </div>
                            </div>
                        </div>
                        <div class="pane-code">
                            <div class="code-render">
                                ${hunk.map(l => this.renderLine(l)).join('')}
                            </div>
                        </div>
                    </div>
                `;
                return slide;
            }

            isolateHunk(diff, comp) {
                const lines = diff.split('\n');
                let target = lines.findIndex(l => l.includes(comp));
                if (target === -1) return lines.slice(0, 40);

                const start = Math.max(0, target - 12);
                const end = Math.min(lines.length, target + 28);
                return lines.slice(start, end);
            }

            renderLine(line) {
                let cls = 'diff-line';
                let marker = '&nbsp;';
                if (line.startsWith('+') && !line.startsWith('+++')) {
                    cls += ' diff-add';
                    marker = '+';
                    line = line.substring(1);
                } else if (line.startsWith('-') && !line.startsWith('---')) {
                    cls += ' diff-del';
                    marker = '-';
                    line = line.substring(1);
                } else if (line.startsWith('@@')) {
                    cls += ' hunk-header';
                }

                return `<div class="${cls}"><span class="line-prefix">${marker}</span><span>${this.escape(line)}</span></div>`;
            }

            escape(s) {
                return s.replace(/[&<>"']/g, m => ({'&': '&amp;', '<': '&lt;', '>': '&gt;', '"': '&quot;', "'": '&#39;'})[m]);
            }

            setTab(idx, tab) {
                if (this.currentStep !== idx) return;
                this.currentTab = tab;
                const slide = document.getElementById(`slide-${idx}`);
                slide.querySelectorAll('.tab').forEach(t => t.classList.toggle('active', t.dataset.tab === tab));
                slide.querySelectorAll('.insight-panel').forEach(p => p.classList.remove('active'));
                slide.querySelector(`#${tab}-${idx}`).classList.add('active');
            }

            next() {
                if (this.currentStep < WALKTHROUGH_JSON.length - 1) {
                    this.currentStep++;
                    this.updateUI();
                    if (this.isPlaying) {
                        this.playCurrentAudio();
                    }
                } else if (this.isPlaying) {
                    this.togglePlay();
                }
            }

            prev() {
                if (this.currentStep > 0) {
                    this.currentStep--;
                    this.updateUI();
                    if (this.isPlaying) {
                        this.playCurrentAudio();
                    }
                }
            }

            updateUI() {
                const wrapper = document.getElementById('slides-wrapper');
                wrapper.style.transform = `translateY(-${this.currentStep * 100}vh)`;
                
                document.getElementById('step-count-label').innerText = `STEP ${String(this.currentStep + 1).padStart(2, '0')} // ${String(WALKTHROUGH_JSON.length).padStart(2, '0')}`;
                document.getElementById('progress-fill').style.width = `${((this.currentStep + 1) / WALKTHROUGH_JSON.length) * 100}%`;
                
                document.getElementById('prev-btn').disabled = (this.currentStep === 0);
                document.getElementById('next-btn').disabled = (this.currentStep === WALKTHROUGH_JSON.length - 1);
                this.currentTab = 'logic'; // Reset tab on move
            }

            togglePlay() {
                this.isPlaying = !this.isPlaying;
                const icon = document.getElementById('play-icon');
                const btn = document.getElementById('play-btn');

                if (this.isPlaying) {
                    icon.innerHTML = `<svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><rect x="6" y="4" width="4" height="16"></rect><rect x="14" y="4" width="4" height="16"></rect></svg>`;
                    btn.classList.add('playing');
                    this.playCurrentAudio();
                } else {
                    icon.innerHTML = `<svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M8 5v14l11-7z"/></svg>`;
                    btn.classList.remove('playing');
                    this.pauseCurrentAudio();
                }
            }
        }

        const app = new App();
    </script>

</body></html>